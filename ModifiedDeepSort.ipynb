{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/abhyantrika/nanonets_object_tracking/\n",
    "\n",
    "from ObjectTracking_DeepSORT.deep_sort import nn_matching\n",
    "from ObjectTracking_DeepSORT.deep_sort.detection import Detection\n",
    "from ObjectTracking_DeepSORT.deep_sort.tracker import Tracker\n",
    "from ObjectTracking_DeepSORT.deep_sort import generate_detections as gdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Object_tracking(output_path):\n",
    "    # Definition of the parameters\n",
    "    max_cosine_distance = 0.7\n",
    "    nn_budget = None\n",
    "    counter = 0\n",
    "    \n",
    "    #initialize deep sort object\n",
    "    model_filename = './model_data/mars-small128.pb'\n",
    "    encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
    "    metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "    tracker = Tracker(metric)\n",
    "\n",
    "    \n",
    "    objs = './Videos/Objects'\n",
    "    frames = './Videos/frames'\n",
    "    uniquePeople = './Videos/Tracked/UniquePeople/'\n",
    "    \n",
    "    if not os.path.isdir(uniquePeople):\n",
    "        os.mkdir(uniquePeople)\n",
    "    \n",
    "\n",
    "    objlist = []\n",
    "    for img in os.listdir(objs):\n",
    "        if img.endswith('.jpg'):\n",
    "            objlist.append(img)\n",
    "        \n",
    "    objlist = sorted(objlist, key=lambda x: int(x.split('_')[0]))\n",
    "    \n",
    "    def findObjs(frameNumber,objlist):\n",
    "        paths = []\n",
    "        for obj in objlist:\n",
    "            if obj.split('_')[0] == frameNumber:\n",
    "                paths.append(obj)\n",
    "            elif int(obj.split('_')[0]) > int(frameNumber):\n",
    "                return paths\n",
    "        return paths\n",
    "\n",
    "    framelist = []\n",
    "    for img in os.listdir(frames):\n",
    "        if img.endswith('.jpg'):\n",
    "            framelist.append(img)\n",
    "    \n",
    "    framelist = sorted(framelist, key=lambda x: int(x.split('.')[0]))\n",
    "    \n",
    "    for img in framelist:\n",
    "        boxes, scores, names = [], [], []\n",
    "\n",
    "        frameNumber = img[:img.find('.jpg')]\n",
    "        imagePath = frames+'/'+img\n",
    "        original_frame = cv2.imread(imagePath, cv2.COLOR_BGR2RGB)\n",
    "        original_frame = cv2.cvtColor(original_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        paths = findObjs(frameNumber,objlist)\n",
    "\n",
    "        for path in paths:\n",
    "\n",
    "            data = path[:path.find('.jpg')].split('_')\n",
    "            # 0 frames, 1 obj id, 2 centerpoint, 3 min coordinate, 4 max coordinate\n",
    "            min_coordinate = data[3].split('COMMA')\n",
    "            xmin = int(min_coordinate[0].replace('(',''))\n",
    "            ymin = int(min_coordinate[1].replace(')',''))\n",
    "\n",
    "            max_coordinate = data[4].replace('.jpg','').split('COMMA')\n",
    "            xmax = int(max_coordinate[0].replace('(',''))\n",
    "            ymax = int(max_coordinate[1].replace(')',''))\n",
    "\n",
    "\n",
    "            #(x, y, width, height)\n",
    "            box = [xmin,ymin,xmax-xmin,ymax-ymin]\n",
    "\n",
    "            boxes.append(box)\n",
    "            scores.append(0.9)\n",
    "            names.append('1')\n",
    "\n",
    "\n",
    "        # Obtain all the detections for the given frame.\n",
    "        boxes = np.array(boxes) \n",
    "        names = np.array(names)\n",
    "        scores = np.array(scores)\n",
    "        features = np.array(encoder(original_frame, boxes))\n",
    "        detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(boxes, scores, names, features)]\n",
    "\n",
    "        # Pass detections to the deepsort object and obtain the track information.\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Obtain info from the tracks\n",
    "        tracked_bboxes = []\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 5:\n",
    "                continue \n",
    "            bbox = track.to_tlbr() \n",
    "            class_name = track.get_class() \n",
    "            tracking_id = track.track_id \n",
    "            index = 1 \n",
    "            tracked_bboxes.append(bbox.tolist() + [tracking_id, index]) \n",
    "\n",
    "        \n",
    "        # draw detection on frame\n",
    "        image = original_frame.copy()\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        for b in tracked_bboxes:\n",
    "            counter += 1\n",
    "            coor = np.array(b[:4], dtype=np.int32)\n",
    "            image_h, image_w, _ = image.shape\n",
    "            fontScale = 0.5\n",
    "            score = b[4]\n",
    "            bbox_color = (255,255,255)\n",
    "            bbox_thick = int(0.6 * (image_h + image_w) / 600)\n",
    "            c1, c2 = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "            \n",
    "            fullPath = uniquePeople+str(score)+'_'+str(counter)+'.jpg'\n",
    "\n",
    "            if coor[0] < 0:\n",
    "                coor[0] = 0\n",
    "            if coor[1] < 0:\n",
    "                coor[1] = 0\n",
    "            if coor[2] < 0:\n",
    "                coor[2] = 0\n",
    "            if coor[3] < 0:\n",
    "                coor[3] = 0\n",
    "\n",
    "            obj = cv2.resize(original_frame[coor[1]:(coor[3]),coor[0]:(coor[2])],(250,500))\n",
    "            obj = cv2.cvtColor(obj,cv2.COLOR_BGR2RGB)\n",
    "            cv2.imwrite(fullPath,obj)\n",
    "        \n",
    "            cv2.rectangle(image, c1, c2, bbox_color, bbox_thick)\n",
    "            bbox_mess = '%s: %.2f' % ('person', score)\n",
    "            t_size = cv2.getTextSize(bbox_mess, 0, fontScale, thickness=bbox_thick//2)[0]\n",
    "            cv2.rectangle(image, c1, (c1[0] + t_size[0], c1[1] - t_size[1] - 3), bbox_color, -1)  # filled\n",
    "            cv2.putText(image, bbox_mess, (c1[0], c1[1]-2), cv2.FONT_HERSHEY_SIMPLEX, fontScale, (0, 0, 0), bbox_thick//2, lineType=cv2.LINE_AA)\n",
    "            \n",
    "        final_out_path = output_path + frameNumber + '.jpg'\n",
    "        \n",
    "        if final_out_path != '': \n",
    "            cv2.imwrite(final_out_path,image)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = './Videos/Tracked/'\n",
    "\n",
    "if not os.path.isdir(out_path):\n",
    "    os.mkdir(out_path)\n",
    "\n",
    "Object_tracking(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
