{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pathlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = './Videos/frames'\n",
    "images = list(pathlib.Path(images).glob('**/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for img in images:\n",
    "    i = {\n",
    "        'frame': int(str(img).split('\\\\')[-1].replace('.jpg','')),\n",
    "        'path': img\n",
    "    }\n",
    "    files.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(files, key=lambda k: k['frame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1'\n",
    "detector = hub.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawBoxes(img, boxes, scores, classes, accuracy=0.4, boxes_shaped=False, scaled=False, color=(255, 0, 0), box_thickness=5):\n",
    "    \n",
    "    imgCopy = img.copy()\n",
    "    if boxes_shaped==False:\n",
    "        boxes = np.array(boxes).reshape(boxes.shape[1:])\n",
    "\n",
    "    count = 0\n",
    "    for ymin, xmin, ymax, xmax in boxes:\n",
    "        if scaled==False:\n",
    "            xscaler, yscaler = img.shape[1],img.shape[0]\n",
    "            ymin = math.ceil(ymin*yscaler)\n",
    "            ymax = math.ceil(ymax*yscaler)\n",
    "            xmin = math.ceil(xmin*xscaler)\n",
    "            xmax = math.ceil(xmax*xscaler)\n",
    "        if classes[count] == 1:\n",
    "            if scores[count] > accuracy:\n",
    "                start_point = (xmin,ymin)\n",
    "                end_point = (xmax,ymax)\n",
    "                                \n",
    "                centerPoint = ((math.ceil((xmax-xmin)/2))+xmin,(math.ceil((ymax-ymin)/2)+ymin))\n",
    "                xx,yy = centerPoint\n",
    "                xx += 1\n",
    "                yy += 1\n",
    "                \n",
    "                cp1 = (xx,yy)\n",
    "                pointColor = (255,0,0)\n",
    "                \n",
    "                cv2.rectangle(imgCopy, start_point, end_point, color, box_thickness)\n",
    "                cv2.rectangle(imgCopy, centerPoint, cp1, pointColor, 10)\n",
    "        count += 1\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(imgCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveObjects(img, boxes, output_path, scores, classes, frame_number, accuracy=0.4, boxes_shaped=False, scaled=False):\n",
    "\n",
    "    if boxes_shaped==False:\n",
    "        boxes = np.array(boxes).reshape(boxes.shape[1:])\n",
    "        \n",
    "    count = 0\n",
    "    img_count = 0\n",
    "    for ymin, xmin, ymax, xmax in boxes:\n",
    "        # if the object is a person (class[count] == 1)\n",
    "        if classes[count] == 1:\n",
    "            # if the models confident beyond a threshold, i.e. 0.4\n",
    "            if scores[count] > accuracy:\n",
    "                # scale the data if needed by multiplying y coordniates \n",
    "                # by height of image and x coordinates by width of image\n",
    "                if scaled==False:\n",
    "                    xscaler, yscaler = img.shape[1],img.shape[0]\n",
    "                    ymin = math.ceil(ymin*yscaler)\n",
    "                    ymax = math.ceil(ymax*yscaler)\n",
    "                    xmin = math.ceil(xmin*xscaler)\n",
    "                    xmax = math.ceil(xmax*xscaler)\n",
    "                \n",
    "                \n",
    "                centerPoint = '('+str((math.ceil((xmax-xmin)/2))+xmin)+'COMMA'+str((math.ceil((ymax-ymin)/2)+ymin))+')'\n",
    "                sp = '('+str(xmin)+'COMMA'+str(ymin)+')'\n",
    "                ep = '('+str(xmax)+'COMMA'+str(ymax)+')'\n",
    "                obj = cv2.resize(cv2.cvtColor(img[ymin:ymax,xmin:xmax],cv2.COLOR_BGR2RGB),(250,500))        \n",
    "                fullPath = output_path+'/'+frame_number+'_'+str(img_count)+'_'+centerPoint+'_'+sp+'_'+ep+'.jpg'\n",
    "                cv2.imwrite(fullPath,obj)\n",
    "                img_count += 1\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPeople(imagePath, save=False, outputPath=None, display=True, accuracy=0.4):\n",
    "    \n",
    "    img = cv2.imread(imagePath)\n",
    "    \n",
    "    frame_number = imagePath.split('\\\\')[-1].replace('.jpg','')\n",
    "    \n",
    "    # Change to a RGB image\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Reshape the image from (720, 1280, 3) to (1, 720, 1280, 3), which is needed to input into the model\n",
    "    rsimg = img[np.newaxis, ...]\n",
    "    \n",
    "    #detect the objects\n",
    "    detector_output = detector(rsimg)\n",
    "    \n",
    "    # Get an array of the different classes detected\n",
    "    class_ids = detector_output[\"detection_classes\"]\n",
    "    classes = list(class_ids.numpy()[0])\n",
    "\n",
    "    # Get an array of the confidence scores for each object\n",
    "    d_scores = detector_output['detection_scores']\n",
    "    scores = list(d_scores.numpy()[0])\n",
    "\n",
    "    # Get the boxes that surround the objects\n",
    "    d_boxes = detector_output[\"detection_boxes\"]\n",
    "    \n",
    "    if display:\n",
    "        drawBoxes(img,d_boxes, scores, classes, accuracy=accuracy, color=(0,255,0), box_thickness=2)\n",
    "        \n",
    "    if save:\n",
    "        if outputPath == None:\n",
    "            outputPath = './Videos/Objects'\n",
    "            \n",
    "        saveObjects(img, d_boxes, outputPath, scores, classes, frame_number, accuracy=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(files):\n",
    "    detectPeople(str(file['path']), save=True, display=False)\n",
    "    \n",
    "print('Objects have been saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
